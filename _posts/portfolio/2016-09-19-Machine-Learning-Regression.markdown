---
layout: post
title:  "Machine Learning: Regression"
date:   2016-09-19 18:11:16
categories: portfolio
featured: true
featured_image: "../../assets/img/project.png"
tags: Coursera
---


## Week 1: Simple Linear Regression
This assignment uses linear regression to predict house prices
[nbviewer](http://nbviewer.jupyter.org/github/DFoly/Machine-Learning/blob/master/Python/Regression/RegressionWeek1/week-1-simple-regression-assignment-blank.ipynb)

## Week 2: Multiple Linear Regression
This builds upon the previous week using more variables as predictors of house prices
[nbviewer]()

## Week 3: Polynomial Regression
Using polynomial regression to try and improve the fit of our model and visualise the effect of adding higher order polynomial terms on our line of best fit.
[nbviewer](http://nbviewer.jupyter.org/github/DFoly/Machine-Learning/blob/master/Python/Regression/RegressionWeek3/week-3-polynomial-regression-assignment-blank.ipynb)

## Week 4 part 1: Ridge Regression (L2 regularisation)
We run ridge regression to try and avoid overfitting caused by adding polynomial terms to our regresssion. To find the optimal value of our L2 paramter we run Kfold cross validation.
[nbviewer]()

## Week 4 part 2: Ridge Regression with Gradient Descent
In this final assignment we implement ridge regression using a gradient descent algorithm.
[nbviewer]()
